{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.032566218796731"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(2, scale=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k杆摇臂机\n",
    "class K_armed_bandit(object):\n",
    "    def __init__(self, num_k, seed= False):\n",
    "        if seed:\n",
    "            np.random.seed(1)\n",
    "        self.loc = np.round(np.random.normal(size= num_k), decimals= 2)\n",
    "        self.actions_list = np.arange(num_k).astype(np.int)\n",
    "        \n",
    "    def __call__(self, action):\n",
    "        return self.run(action)\n",
    "        \n",
    "    def run(self, action):\n",
    "        return np.random.normal(self.loc[action], scale= 0.1)\n",
    "    \n",
    "    def get_parms(self):\n",
    "        return self.loc\n",
    "    \n",
    "    def get_actions_list(self):\n",
    "        return self.actions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 environment,\n",
    "                 epsilon_greedy= 1e-1,\n",
    "                 step_size = 1e-3,\n",
    "                 initial= 0.):\n",
    "        \n",
    "        self.environment = environment\n",
    "        self.actions_list = environment.get_actions_list()\n",
    "        self.num_actions = len(self.actions_list)\n",
    "        self.greedy = 1.- epsilon_greedy\n",
    "        self.step_size = step_size\n",
    "        self.average_reward = 0\n",
    "        self.action_value_array = np.array([initial] * self.num_actions)\n",
    "        self.action_list = []\n",
    "        self.reward_list = []\n",
    "        \n",
    "    def __call__(self, num_episodes= 1e3):\n",
    "        for i in range(int(num_episodes)):\n",
    "            self.step()\n",
    "            \n",
    "    def action_selection(self):\n",
    "        if np.random.uniform() > self.greedy:\n",
    "            action = np.random.choice(self.actions_list)\n",
    "        else:\n",
    "            action = self.get_argmax_action_value()\n",
    "        return action\n",
    "    \n",
    "    def action_reward(self, action):\n",
    "        return self.environment(action)\n",
    "    \n",
    "    def get_argmax_action_value(self):\n",
    "        index = np.argmax(self.action_value_array)\n",
    "        return self.actions_list[index]\n",
    "    \n",
    "    def get_next_action_value(self, action, reward):\n",
    "        action_value = self.action_value_array[action]\n",
    "        next_action_value = action_value + self.step_size * (reward - action_value)\n",
    "        self.action_value_array[action] = next_action_value\n",
    "    \n",
    "    def step(self):\n",
    "        action = self.action_selection()\n",
    "        reward = self.action_reward(action)\n",
    "        self.get_next_action_value(action, reward)\n",
    "        # 记录训练过程\n",
    "        self.action_list.append(action)\n",
    "        self.reward_list.append(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02, -1.52,  0.92, -2.14, -0.26, -0.73,  0.28,  0.85,  1.46,\n",
       "       -0.75,  0.11,  0.32, -1.95,  0.32,  1.6 , -1.35, -1.39, -0.34,\n",
       "        1.65, -0.59,  0.61, -0.65,  0.21,  1.29,  1.5 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment = K_armed_bandit(25)\n",
    "environment.get_parms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "agent = Agent(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01880002, -1.48622212,  0.91994128, -2.09869382, -0.25448965,\n",
       "       -0.71631271,  0.27327057,  0.83432282,  1.4343519 , -0.73318404,\n",
       "        0.10619266,  0.31116251, -1.91339544,  0.31150261,  1.56916426,\n",
       "       -1.32237158, -1.36305728, -0.33369344,  1.65575383, -0.57869061,\n",
       "        0.59856524, -0.63780024,  0.20490615,  1.26386248,  1.47364477])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action_value_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
